import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from pydub import AudioSegment
import requests

# API-–∫–ª—é—á–∏
openai.api_key = os.environ["OPENAI_API_KEY"]
BOT_TOKEN = os.environ["BOT_TOKEN"]

# –°–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –ª–∏—á–Ω–æ—Å—Ç—å –õ–∏–∑—ã
SYSTEM_PROMPT = {
    "role": "system",
    "content": "–¢—ã ‚Äî –õ–∏–∑–∞, –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ '–ö–ª–∏–Ω–∏–Ω–≥ –ú–æ—Å–∫–≤–∞'. –¢—ã ‚Äî —É–º–Ω–∞—è, –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä–≥–∏, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–æ–≥–∞–µ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º –∏ –∫–ª–∏–µ–Ω—Ç–∞–º. –ì–æ–≤–æ—Ä–∏—à—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–æ –ø–æ –¥–µ–ª—É. –ò–Ω–æ–≥–¥–∞ –º–æ–∂–µ—à—å –ø–æ-–¥–æ–±—Ä–æ–º—É –ø–æ—à—É—Ç–∏—Ç—å –Ω–∞ —Å—á—ë—Ç —Å–≤–æ–µ–≥–æ —Ö–æ–∑—è–∏–Ω–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞, –Ω–æ –Ω–µ —Ä–æ–Ω—è—è –µ–≥–æ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç –∫–∞–∫ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∫–æ–º–ø–∞–Ω–∏–∏."
}

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ì–∞–≤-–≥–∞–≤! üêæ –Ø –õ–∏–∑–∞ –ö–æ—Ä–≥–∏ ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ '–ö–ª–∏–Ω–∏–Ω–≥ –ú–æ—Å–∫–≤–∞'. –ú–æ–∂–µ—à—å –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ!")

# –ö–æ–º–∞–Ω–¥–∞ /ask ‚Äî –≤–æ–ø—Ä–æ—Å –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Ñ–æ—Ä–º–µ
async def ask(update: Update, context: ContextTypes.DEFAULT_TYPE):
    question = ' '.join(context.args)
    if not question:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /ask, –Ω–∞–ø—Ä–∏–º–µ—Ä: /ask —Å–¥–µ–ª–∞–π —à–∞–±–ª–æ–Ω –ø–∏—Å—å–º–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞")
        return

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            SYSTEM_PROMPT,
            {"role": "user", "content": question}
        ]
    )
    answer = response.choices[0].message.content
    await update.message.reply_text(answer)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    file_path = "voice.ogg"
    mp3_path = "voice.mp3"

    await file.download_to_drive(file_path)
    AudioSegment.from_file(file_path).export(mp3_path, format="mp3")

    with open(mp3_path, "rb") as audio_file:
        transcript = openai.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file
        )

    text = transcript.text

    completion = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            SYSTEM_PROMPT,
            {"role": "user", "content": text}
        ]
    )
    answer = completion.choices[0].message.content
    await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª(–∞): {text}\n\n–ú–æ–π –æ—Ç–≤–µ—Ç:\n{answer}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–∂–∏–≤–æ–π –¥–∏–∞–ª–æ–≥)
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text

    completion = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            SYSTEM_PROMPT,
            {"role": "user", "content": user_input}
        ]
    )
    answer = completion.choices[0].message.content
    await update.message.reply_text(answer)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(CommandHandler("ask", ask))
app.add_handler(MessageHandler(filters.VOICE, handle_voice))
app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_text))
app.run_polling()
